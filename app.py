
import os
import re
import requests
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from transformers import pipeline
import whisper

# =========================
# CONFIG STREAMLIT
# =========================
st.set_page_config(page_title="Conectividad SIG ‚Äì Dashboard", layout="wide", page_icon="üìä")
st.title("üìä Conectividad y Habilidades Digitales ‚Äì Dashboard")
st.caption("Flujo 100% autom√°tico: KoboToolbox ‚Üí Transcripci√≥n y an√°lisis ‚Üí Visualizaci√≥n")

# =========================
# TOKEN Y FORM_ID DESDE SECRETS
# =========================
try:
    API_TOKEN = st.secrets["API_TOKEN"]
    FORM_ID = st.secrets["FORM_ID"]
except Exception:
    st.error("‚ùå Faltan secretos API_TOKEN y FORM_ID en Settings ‚Üí Secrets de Streamlit Cloud.")
    st.stop()

BASE_URL = "https://eu.kobotoolbox.org/api/v2/assets/"
HEADERS = {"Authorization": f"Token {API_TOKEN}"}

# =========================
# FUNCIONES
# =========================
@st.cache_data(show_spinner=False)
def fetch_kobo_csv() -> pd.DataFrame:
    url = f"{BASE_URL}{FORM_ID}/data.csv"
    r = requests.get(url, headers=HEADERS, timeout=60)
    if r.status_code != 200:
        st.error(f"‚ùå Error {r.status_code} al obtener CSV desde Kobo.")
        return pd.DataFrame()
    from io import StringIO
    return pd.read_csv(StringIO(r.text))

def download_audio_bytes(url: str) -> bytes:
    try:
        r = requests.get(url, headers=HEADERS, timeout=120)
        if r.status_code == 200:
            return r.content
    except Exception:
        return None
    return None

@st.cache_resource(show_spinner=False)
def load_whisper_model(model_size: str = "base"):
    return whisper.load_model(model_size)

@st.cache_resource(show_spinner=False)
def load_sentiment_pipeline():
    return pipeline("sentiment-analysis", model="cardiffnlp/twitter-xlm-roberta-base-sentiment")

def transcribe_audio(audio_bytes: bytes, whisper_model) -> str:
    if not audio_bytes:
        return ""
    import tempfile, os
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
        tmp.write(audio_bytes)
        tmp_path = tmp.name
    try:
        result = whisper_model.transcribe(tmp_path, language="es")
        text = (result.get("text") or "").strip()
    except Exception:
        text = ""
    finally:
        try:
            os.remove(tmp_path)
        except Exception:
            pass
    return text

def map_sentiment(label: str) -> str:
    label = (label or "").lower()
    if "neg" in label: return "Negativo"
    if "pos" in label: return "Positivo"
    if "neu" in label: return "Neutro"
    return "Sin texto"

STOPWORDS = set("""
a al algo algunas algunos ante antes aquella aquellas aquello aquellos aqu√≠ as√≠ aun aunque bajo bien cada casi como con contra cu√°l cuales cuando de del desde donde dos el ella ellas ello ellos en entre era erais eran eras eres es esa esas ese esos esta estaban est√°is estamos est√°n estar est√© esto estos fue fueron ha haber hab√≠a hab√©is hab√≠a hab√≠an hago hasta hay la las le les lo los m√°s me m√≠ m√≠a m√≠as m√≠o m√≠os mientras muy nos nosotras nosotros nuestra nuestras nuestro nuestros o os otra otras otro otros para pero poca pocas poco pocos podr√° porque por qu√© que quien quienes se sea seg√∫n ser si sido sin sobre sois somos son su sus tambi√©n te tendr√° tiene todas toda todos todo tras t√∫ tus un una unas unos y ya yo
""".split())

def extract_keywords(text: str, top_n: int = 10) -> str:
    if not isinstance(text, str) or not text.strip():
        return ""
    t = text.lower()
    t = re.sub(r"[^\w√°√©√≠√≥√∫√±√º ]+", " ", t, flags=re.UNICODE)
    tokens = [tok for tok in t.split() if len(tok) >= 4 and tok not in STOPWORDS]
    from collections import Counter
    freq = Counter(tokens)
    return ", ".join([w for w, _ in freq.most_common(top_n)])

# =========================
# EJECUCI√ìN
# =========================
st.subheader("1) Descargando datos de KoboToolbox")
df_raw = fetch_kobo_csv()
st.write(f"**Debug:** Registros descargados: {len(df_raw)}")

if df_raw.empty:
    st.warning("No se pudo cargar datos desde Kobo.")
    st.stop()

# Detectar columnas *_URL
url_cols = [c for c in df_raw.columns if c.endswith("_URL")]
st.write(f"**Debug:** Columnas de audio detectadas: {url_cols}")

if not url_cols:
    st.warning("No se detectaron columnas *_URL en el CSV. Revisa la exportaci√≥n.")
    st.stop()

# Construir DF largo
rows = []
for i, rec in df_raw.iterrows():
    municipio = rec.get("Municipio", "")
    barrio = rec.get("Barrio/Vereda", "")
    lat = rec.get("_Por favor captura tu ubicaci√≥n (GPS)_latitude")
    lon = rec.get("_Por favor captura tu ubicaci√≥n (GPS)_longitude")
    for col in url_cols:
        pregunta = col.replace("_URL", "")
        audio_url = rec.get(col)
        rows.append({
            "pregunta": pregunta,
            "municipio": municipio,
            "barrio_vereda": barrio,
            "audio_url": audio_url,
            "lat": lat,
            "lon": lon,
            "transcripcion": "",
            "sentimiento": "",
            "palabras_clave": ""
        })

